<html>
  <head />
  <body>
    <p>For this Tennis project, I implemented MADDPPG algorithm for training the Tennis env with two players.</p>
    <p>It has been trained by running 5837 episodes, and having average of 0.52 in the end.</p>
    <p>For the chosen hyper parameters, I used:
      n_episodes=10000,        # Number of episodes
      max_t=1000-,             # Number of steps per episode
      BUFFER_SIZE = int(1e6)  # replay buffer size
      BATCH_SIZE = 128        # minibatch size
      GAMMA = 0.99            # discount factor
      TAU = 1e-3              # for soft update of target parameters                                                                                                                 LR_ACTOR = 1e-4         # learning rate of the actor
      LR_CRITIC = 1e-4        # learning rate of the critic
      WEIGHT_DECAY = 0        # L2 weight decay
    </p>
    <p>
        MADDPG algotithm overview:
        MADDPG (Multi-agent Deep Deterministic Policy Gradient) are trained with two separate agents with its own DDPG agent,
        but sharing the same state and rewards. Each agent's critic is trained with all the observations from all agents, but
        each agent's actor is trained on only its local observations.
    </p>
    <p> Model architecture:
      The actor neural network consists of three layers:
      - A fully connected layer with input of state size and output of 512 units
      - A fully connected layer with input of 512 units and output of 256 units
      - A fully connected layer with input of 256 units and output of the action size

      The critic neural network consists of three layers:
      - A fully connected layer with input of state size and output of 96 units
      - A fully connected layer with input of 96 units and action size and output of 96 units
      - A fully connected layer with input of 96 units and output of 1
    </p>
    <p> Furthur improvements:
      We can add Batch normalization to the existing implementation. We can also try out different algorithms like PPO, TRPO or TNPG.
      We can also improve the overall hyperparamter search with some grid search opportunities, and also potentially searching for a better neural network with AutoML search.
    </p>
    <img src="results.png" />
  </body>
</html>
